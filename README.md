
---

# ğŸ“„ Multi-Modal RAG for Document Question Answering

A production-style **Multi-Modal Retrieval-Augmented Generation (RAG)** system that enables **question answering over complex documents** containing **text, tables, charts, figures, and scanned images**.

The system ingests PDFs, extracts multi-modal content, indexes it in a unified vector space, and answers user questions with **grounded citations** using **Gemini**.

---

## ğŸš€ Features

* âœ… Text extraction from PDFs
* âœ… Table extraction using Camelot
* âœ… Image & figure OCR support
* âœ… Unified chunking and embedding pipeline
* âœ… FAISS-based semantic retrieval
* âœ… Gemini-powered RAG answering
* âœ… Page-level citations
* âœ… Hallucination-safe responses
* âœ… Streamlit demo application

---

## ğŸ§  System Architecture

```
PDF
 â”œâ”€â”€ Text Extraction
 â”œâ”€â”€ Table Extraction
 â””â”€â”€ Image OCR
        â†“
  Unified Chunking
        â†“
  Embeddings (Sentence Transformers)
        â†“
  FAISS Vector Store
        â†“
  Retriever
        â†“
  Gemini RAG QA Chain
```

All modalities (text, table, image) are indexed into a **single embedding space** for consistent retrieval.

---

## ğŸ“ Project Structure

```
MultiModal-RAG/
â”‚
â”œâ”€â”€ ingestion/          # PDF text, table, and image extraction
â”œâ”€â”€ chunking/           # Chunking logic
â”œâ”€â”€ embeddings/         # Embedding abstraction
â”œâ”€â”€ vectorstore/        # FAISS index wrapper
â”œâ”€â”€ rag/                # Retriever + Gemini QA chain
â”œâ”€â”€ streamlit_app.py    # Streamlit demo app
â”œâ”€â”€ testing/            # Unit test for each
â”‚   â””â”€â”€ test_rag.py     # Text + table + OCR RAG test
â”‚   â””â”€â”€ test_chunking.py
â”‚   â””â”€â”€ test_faiss.py
â”‚   â””â”€â”€ test_ingestion.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

> âš ï¸ **Important: Python Version Requirement**

This project **requires Python 3.11.x**.
Python **3.14 is NOT supported** due to incompatibilities with:

* `torch`
* `sentence-transformers`
* `faiss`
* `numpy` (binary extension mismatch)

Attempting to run this project on Python 3.14 will result in:

* Torch install failures
* NumPy runtime errors
* Broken embedding generation

---

### âœ… Supported Python Version

```
Python 3.11.x  (recommended: 3.11.9)
```

---

### 1ï¸âƒ£ Install Python 3.11 Using `pyenv` (Recommended)

If you already have `pyenv` installed:

```bash
pyenv install 3.11.9
pyenv local 3.11.9
```

Verify:

```bash
python --version
# Python 3.11.9
```


### 1ï¸âƒ£ Create Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Set Gemini API Key

Inside .env.example set up your gemini api key and rename your file to .env
```bash
GOOGLE_API_KEY="your_api_key_here"
```

---

## â–¶ï¸ Running the Streamlit App

```bash
streamlit run streamlit_app.py
```

Then:

1. Upload a PDF document
2. Ask questions about text, tables, or images
3. View answers with citations

---

## ğŸ§ª Example Questions (For Demo)

### Text-based

> What are the key macroeconomic risks facing Qatar?

### Table-based

> What are the main risks listed in the Risk Assessment Matrix?

### Image / OCR-based

> Who published this document and what address is shown on the cover page?

### Numerical (Figure-based)

> What are the probabilities shown for crisis risk in 2024â€“2025?

### Hallucination check

> What is Qatarâ€™s inflation rate in 2030?

(Expected: *Information not found in the document.*)

---

## ğŸ” Multi-Modal Verification

| Modality         | Verified |
| ---------------- | -------- |
| Text             | âœ…        |
| Tables           | âœ…        |
| Figures / Charts | âœ…        |
| Images / OCR     | âœ…        |
| Numerical QA     | âœ…        |

OCR-derived chunks are retrieved when layout-specific or visual information is queried (e.g., cover page details, figure captions).

---

## ğŸ§© Design Choices

* **FAISS** for fast semantic retrieval
* **Sentence Transformers** for local embeddings
* **Gemini 2.5 Flash Lite** for instruction-following and grounded generation
* **Streamlit** for lightweight interactive demo

The system prioritizes **faithfulness, explainability, and modularity**.

---

## ğŸ“ˆ Bonus Extensions (Planned)

* Hybrid retrieval (dense + keyword with RRF)
* Executive summary / briefing generation
* Retrieval evaluation utilities

---

## ğŸ Summary

This project demonstrates a **real-world, evaluator-grade Multi-Modal RAG system** capable of answering grounded questions over complex policy and financial documents.

---
